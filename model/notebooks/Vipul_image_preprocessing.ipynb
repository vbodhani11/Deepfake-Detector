{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96f1bd4490e147e196eeb411afe03728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d5617543e1c4926830a40b4ca0ea098",
              "IPY_MODEL_c7ac547fd80d4327bdc82841c220a470",
              "IPY_MODEL_e64db6820ee14bddab0bad3a7c1d29ca"
            ],
            "layout": "IPY_MODEL_399f0138e7c74422a80234020f42f32b"
          }
        },
        "7d5617543e1c4926830a40b4ca0ea098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_305ab9a714914932b96621c9f0a2d01d",
            "placeholder": "​",
            "style": "IPY_MODEL_7d988bf0cdce4fde8764c944418f3084",
            "value": "Videos: 100%"
          }
        },
        "c7ac547fd80d4327bdc82841c220a470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_865b8ead7b2141a8b4b0b950bdc60a3b",
            "max": 1340,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5058f91bdc194d75beba446bd294ced0",
            "value": 1340
          }
        },
        "e64db6820ee14bddab0bad3a7c1d29ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7229805245f44bd6b9a0961b7d1eb5ab",
            "placeholder": "​",
            "style": "IPY_MODEL_3296d19095a64e4db1e507907ce5118e",
            "value": " 1340/1340 [40:24&lt;00:00,  1.98s/it]"
          }
        },
        "399f0138e7c74422a80234020f42f32b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "305ab9a714914932b96621c9f0a2d01d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d988bf0cdce4fde8764c944418f3084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "865b8ead7b2141a8b4b0b950bdc60a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5058f91bdc194d75beba446bd294ced0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7229805245f44bd6b9a0961b7d1eb5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3296d19095a64e4db1e507907ce5118e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiUXVnoC6WB1",
        "outputId": "806c2397-d114-4a51-95ca-99f428d22edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "!pip -q install facenet-pytorch==2.5.3 tqdm>=4.67\n",
        "\n",
        "import os, sys, math, json, traceback, shutil, glob\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "from facenet_pytorch import MTCNN\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2zQ9MyriTHA",
        "outputId": "475f9a71-0eee-429d-e74b-c6d06240e6fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Config\n",
        "# =========================\n",
        "# If your data is in Drive, uncomment these two lines to mount:\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Point this to your DFDC part 2 directory (where the .mp4 files are).\n",
        "INPUT_DIR  = \"/content/drive/MyDrive/DeepLearning/dfdc_train_part_3\"\n",
        "OUTPUT_DIR = \"dfdc_faces_part_3\"   # results will be written here\n",
        "\n",
        "# Frame sampling\n",
        "FRAMES_PER_SECOND = 1        # sample N frames per second\n",
        "MAX_FRAMES_PER_VIDEO = 64    # safety cap (set None to disable)\n",
        "\n",
        "# Face crop\n",
        "FACE_MARGIN_RATIO = 0.2      # 20% margin around detected box\n",
        "MIN_FACE_SIZE = 64           # skip detections smaller than this (in pixels on short edge)\n",
        "\n",
        "# Output image size and normalization\n",
        "TARGET_SIZE = (299, 299)     # width, height\n",
        "NORMALIZE_TO = \"0_1\"         # \"0_1\" or \"neg1_1\"\n",
        "\n",
        "# Save options\n",
        "SAVE_JPEGS = True            # save each processed frame as .jpg\n",
        "SAVE_NPY   = True            # save per-video tensor as .npy\n",
        "\n",
        "# Device for MTCNN\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Make dirs\n",
        "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "KWWHfYTv69FA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Helpers\n",
        "# =========================\n",
        "def normalize_img(img_np: np.ndarray, mode: str = \"0_1\") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    img_np: HxWxC in uint8\n",
        "    returns float32 normalized image\n",
        "    \"\"\"\n",
        "    x = img_np.astype(np.float32) / 255.0\n",
        "    if mode == \"neg1_1\":\n",
        "        x = x * 2.0 - 1.0\n",
        "    return x\n",
        "\n",
        "def expand_box(xyxy, margin_ratio, img_w, img_h):\n",
        "    x1, y1, x2, y2 = xyxy\n",
        "    w = x2 - x1\n",
        "    h = y2 - y1\n",
        "    cx = x1 + w / 2.0\n",
        "    cy = y1 + h / 2.0\n",
        "    m = margin_ratio * max(w, h)\n",
        "    new_w = w + 2*m\n",
        "    new_h = h + 2*m\n",
        "    nx1 = max(0, int(round(cx - new_w/2)))\n",
        "    ny1 = max(0, int(round(cy - new_h/2)))\n",
        "    nx2 = min(img_w, int(round(cx + new_w/2)))\n",
        "    ny2 = min(img_h, int(round(cy + new_h/2)))\n",
        "    return nx1, ny1, nx2, ny2\n",
        "\n",
        "def pick_largest_box(boxes: np.ndarray) -> Optional[np.ndarray]:\n",
        "    if boxes is None or len(boxes) == 0:\n",
        "        return None\n",
        "    areas = (boxes[:,2]-boxes[:,0]) * (boxes[:,3]-boxes[:,1])\n",
        "    idx = int(np.argmax(areas))\n",
        "    return boxes[idx]\n",
        "\n",
        "def ensure_dir(p: Path):\n",
        "    p.mkdir(parents=True, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "rA9kdh7V7Km5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Initialize detector\n",
        "# =========================\n",
        "# keep_all=True gives all faces; we'll pick the largest for consistency\n",
        "mtcnn = MTCNN(keep_all=True, device=DEVICE, thresholds=[0.6, 0.7, 0.7])\n"
      ],
      "metadata": {
        "id": "IXJSt2y67OLB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Processing loop\n",
        "# =========================\n",
        "video_paths = sorted([p for p in Path(INPUT_DIR).glob(\"*.mp4\")])\n",
        "\n",
        "if not video_paths:\n",
        "    print(f\"No .mp4 files found in {INPUT_DIR}. Check your path.\")\n",
        "else:\n",
        "    print(f\"Found {len(video_paths)} videos.\")\n",
        "\n",
        "error_log = []\n",
        "\n",
        "for vpath in tqdm(video_paths, desc=\"Videos\"):\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(str(vpath))\n",
        "        if not cap.isOpened():\n",
        "            raise RuntimeError(\"Could not open video\")\n",
        "\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        fps = fps if fps and fps > 0 else 30.0\n",
        "        step = max(1, int(round(fps / FRAMES_PER_SECOND)))\n",
        "\n",
        "        # Output folders\n",
        "        vname = vpath.stem\n",
        "        out_dir = Path(OUTPUT_DIR) / vname\n",
        "        if SAVE_JPEGS:\n",
        "            ensure_dir(out_dir)\n",
        "\n",
        "        processed_frames = []\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        save_count = 0\n",
        "        read_idx = 0\n",
        "\n",
        "        while True:\n",
        "            ret = cap.grab()  # fast skip\n",
        "            if not ret:\n",
        "                break\n",
        "            if read_idx % step != 0:\n",
        "                read_idx += 1\n",
        "                continue\n",
        "\n",
        "            # retrieve frame at this index\n",
        "            ret, frame = cap.retrieve()\n",
        "            if not ret:\n",
        "                read_idx += 1\n",
        "                continue\n",
        "\n",
        "            # BGR -> RGB\n",
        "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            pil_img = Image.fromarray(rgb)\n",
        "\n",
        "            # detect faces\n",
        "            boxes, probs = mtcnn.detect(pil_img)\n",
        "            if boxes is None or len(boxes) == 0:\n",
        "                read_idx += 1\n",
        "                continue\n",
        "\n",
        "            # pick largest face\n",
        "            box = pick_largest_box(boxes)\n",
        "            img_h, img_w = rgb.shape[:2]\n",
        "\n",
        "            # expand with margin\n",
        "            x1, y1, x2, y2 = expand_box(box, FACE_MARGIN_RATIO, img_w, img_h)\n",
        "\n",
        "            # skip tiny faces\n",
        "            if min(x2-x1, y2-y1) < MIN_FACE_SIZE:\n",
        "                read_idx += 1\n",
        "                continue\n",
        "\n",
        "            # crop + resize\n",
        "            crop = rgb[y1:y2, x1:x2]\n",
        "            if crop.size == 0:\n",
        "                read_idx += 1\n",
        "                continue\n",
        "\n",
        "            crop_resized = cv2.resize(crop, TARGET_SIZE, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "            # save jpeg (uint8)\n",
        "            if SAVE_JPEGS:\n",
        "                out_file = out_dir / f\"{vname}_{save_count:05d}.jpg\"\n",
        "                cv2.imwrite(str(out_file), cv2.cvtColor(crop_resized, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            # normalized float\n",
        "            norm = normalize_img(crop_resized, NORMALIZE_TO)\n",
        "            processed_frames.append(norm)\n",
        "\n",
        "            save_count += 1\n",
        "            read_idx += 1\n",
        "\n",
        "            if MAX_FRAMES_PER_VIDEO is not None and save_count >= MAX_FRAMES_PER_VIDEO:\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        # save npy (N, 299, 299, 3), float32\n",
        "        if SAVE_NPY and processed_frames:\n",
        "            arr = np.stack(processed_frames, axis=0).astype(np.float32)\n",
        "            np.save(str(Path(OUTPUT_DIR) / f\"{vname}.npy\"), arr)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_info = {\n",
        "            \"video\": str(vpath),\n",
        "            \"error\": repr(e),\n",
        "            \"trace\": traceback.format_exc(limit=1)\n",
        "        }\n",
        "        error_log.append(error_info)\n",
        "\n",
        "# Write error log if any\n",
        "if error_log:\n",
        "    with open(Path(OUTPUT_DIR) / \"errors.json\", \"w\") as f:\n",
        "        json.dump(error_log, f, indent=2)\n",
        "    print(f\"Completed with {len(error_log)} errors. See errors.json in {OUTPUT_DIR}.\")\n",
        "else:\n",
        "    print(\"All videos processed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "96f1bd4490e147e196eeb411afe03728",
            "7d5617543e1c4926830a40b4ca0ea098",
            "c7ac547fd80d4327bdc82841c220a470",
            "e64db6820ee14bddab0bad3a7c1d29ca",
            "399f0138e7c74422a80234020f42f32b",
            "305ab9a714914932b96621c9f0a2d01d",
            "7d988bf0cdce4fde8764c944418f3084",
            "865b8ead7b2141a8b4b0b950bdc60a3b",
            "5058f91bdc194d75beba446bd294ced0",
            "7229805245f44bd6b9a0961b7d1eb5ab",
            "3296d19095a64e4db1e507907ce5118e"
          ]
        },
        "id": "3zVDKuTG7Rcq",
        "outputId": "e108d850-b410-4676-da05-8608cd8ae12e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1340 videos.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96f1bd4490e147e196eeb411afe03728",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Videos:   0%|          | 0/1340 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All videos processed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip everything inside OUTPUT_DIR\n",
        "shutil.make_archive(\"processed_outputs\", 'zip', OUTPUT_DIR)\n",
        "\n",
        "# Trigger download to your local machine\n",
        "files.download(\"processed_outputs.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lKp6Lyg5AmGl",
        "outputId": "1ba38b01-e218-4803-e4fa-d2562390db96"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b10284e5-a9b5-4681-8c63-2c4020c765d3\", \"processed_outputs.zip\", 2666996725)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}